# VAR-CLIP
Implements VAR+CLIP for image generation
## Paper
VAR: https://arxiv.org/abs/2404.02905  
CLIP: https://arxiv.org/abs/2103.00020  
## Some example for class-conditional generation:
<img src="img/concatenated_image.jpg" width="400px"/> . 

### TODO 
- [x] Training on the ImageNet dataset has been completed.
## Training Scripts
The relevant train code will be released soon, please stay tuned~
## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Citations

```bibtex
@misc{unpublished2021clip,
    title  = {CLIP: Connecting Text and Images},
    author = {Alec Radford, Ilya Sutskever, Jong Wook Kim, Gretchen Krueger, Sandhini Agarwal},
    year   = {2021}
}
```
```bibtex
@Article{VAR,
      title={Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction}, 
      author={Keyu Tian and Yi Jiang and Zehuan Yuan and Bingyue Peng and Liwei Wang},
      year={2024},
      eprint={2404.02905},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
* VAR - https://github.com/FoundationVision/VAR
* CLIP - https://github.com/openai/CLIP
